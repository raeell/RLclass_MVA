{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- What we need for a good replay buffer: fixed-size, FIFO behavior, O(1) insertion at the end, O(1) sampling. Limited memory footprint.\n",
    "- [deque](https://docs.python.org/3/library/collections.html#collections.deque) has O(1) insertion time at the end, but O(n) access time (which made me doubt its ability to make a good replay buffer and try an np.array-based solution)\n",
    "- When we draw a mini-batch for DQN, it would be best to receive (separately) an array of states only, an array of actions, an array of rewards, an array of next states and a last array of \"done\", that we can pass these to the Q-network. What's the best way of doing that? Store them separately?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gym import logger\n",
    "import numpy as np\n",
    "logger.set_level(gym.logger.DISABLED)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartpole = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state,_ = cartpole.reset()\n",
    "action = cartpole.action_space.sample()\n",
    "next_state, reward, done, trunc, _ = cartpole.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_size = int(1e6)\n",
    "nb_samples = int(2e6)\n",
    "nb_batches = int(1e4)\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def test_insertion_tqdm(buffer, nb_samples):\n",
    "    state, _ = cartpole.reset()\n",
    "    for _ in trange(nb_samples):\n",
    "        buffer.append(state, action, reward, next_state, done)\n",
    "\n",
    "def test_sampling_tqdm(buffer, nb_batches):\n",
    "    for _ in trange(nb_batches):\n",
    "        buffer.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import gc\n",
    "\n",
    "def test_insertion_timeit(buffer, nb_samples):\n",
    "    print(\"Insertion of\", nb_samples, \"samples:\", \n",
    "      timeit.timeit('memory.append(state,action,reward,next_state,done)', \n",
    "                    globals=globals(), \n",
    "                    setup='gc.enable()', \n",
    "                    number=nb_samples))\n",
    "\n",
    "def test_sampling_timeit(buffer, nb_batches):\n",
    "    print(\"Sampling of\", nb_batches, \"batches:\",\n",
    "          timeit.timeit('memory.sample(batch_size)', \n",
    "                        globals=globals(), \n",
    "                        setup='gc.enable()', \n",
    "                        number=nb_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay buffer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "Transition = namedtuple('Transition', \n",
    "                        ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "\n",
    "# But for the sake of the exercise, we will wrap this in a dedicated class.\n",
    "\n",
    "import random\n",
    "    \n",
    "class ReplayBuffer1(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "    def append(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    def capacity(self):\n",
    "        return self.memory.maxlen\n",
    "    \n",
    "class ReplayBuffer2(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    def capacity(self):\n",
    "        return self.memory.maxlen\n",
    "    \n",
    "class ReplayBuffer3(deque):\n",
    "    def __init__(self, capacity):\n",
    "        super().__init__(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        super().append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self, batch_size)\n",
    "    \n",
    "class ReplayBuffer4(deque):\n",
    "    def __init__(self, capacity):\n",
    "        super().__init__(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        super().append(Transition(state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self, batch_size)\n",
    "\n",
    "class ReplayBuffer5(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = np.empty(capacity, dtype=Transition)\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "        self.size = 0 # number of elements in the buffer\n",
    "    def append(self, *args):\n",
    "        self.data[self.index] = Transition(*args)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "        if self.size < self.capacity:\n",
    "            self.size+=1\n",
    "    def sample(self, batch_size):\n",
    "        #indices = np.random.choice(self.size, size=batch_size, replace=False)\n",
    "        #return self.memory[indices]\n",
    "        return np.random.choice(self.data[:self.size], size=batch_size, replace=False)\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "class ReplayBuffer6(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.data = deque(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.data.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(np.array, list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def capacity(self):\n",
    "        return self.data.maxlen\n",
    "\n",
    "class ReplayBuffer7(deque):\n",
    "    def __init__(self, capacity):\n",
    "        super().__init__(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        super().append(Transition(state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self, batch_size)\n",
    "        return list(map(np.array, list(zip(*batch))))\n",
    "    def capacity(self):\n",
    "        return self.maxlen\n",
    "    \n",
    "class ReplayBuffer8(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.data = deque(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.data.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(torch.Tensor, list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def capacity(self):\n",
    "        return self.data.maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer9:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.data, batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "class ReplayBuffer10:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(torch.Tensor, list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReplayBuffer4([], maxlen=1000000)\n",
      "0\n",
      "ReplayBuffer4([Transition(state=array([ 0.00410543,  0.03742514, -0.0147697 ,  0.02450623], dtype=float32), action=1, reward=1.0, next_state=array([ 0.00485393,  0.23275575, -0.01427957, -0.27279985], dtype=float32), done=False)], maxlen=1000000)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "memory = ReplayBuffer4(replay_buffer_size)\n",
    "print(memory)\n",
    "# len\n",
    "print(len(memory))\n",
    "# append\n",
    "memory.append(state, action, reward, next_state, done)\n",
    "print(memory)\n",
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None None None ... None None None]\n",
      "0\n",
      "[Transition(state=array([ 0.00410543,  0.03742514, -0.0147697 ,  0.02450623], dtype=float32), action=1, reward=1.0, next_state=array([ 0.00485393,  0.23275575, -0.01427957, -0.27279985], dtype=float32), done=False)\n",
      " None None ... None None None]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "memory = ReplayBuffer5(replay_buffer_size)\n",
    "print(memory.data)\n",
    "# len\n",
    "print(len(memory))\n",
    "# append\n",
    "memory.append(state, action, reward, next_state, done)\n",
    "print(memory.data)\n",
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1147464.96it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 611.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.8236342830005015\n",
      "Sampling of 10000 batches: 16.067819274000612\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer1(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:00<00:00, 2682985.16it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 619.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.41561654299948714\n",
      "Sampling of 10000 batches: 15.2426448719998\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer2(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:00<00:00, 2198896.59it/s]\n",
      "100%|██████████| 10000/10000 [00:15<00:00, 627.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.5717196929999773\n",
      "Sampling of 10000 batches: 15.4775857730001\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer3(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:02<00:00, 997902.27it/s] \n",
      "100%|██████████| 10000/10000 [00:16<00:00, 620.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 1.0013630290004585\n",
      "Sampling of 10000 batches: 15.992759149000449\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer4(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1013634.74it/s]\n",
      "100%|██████████| 10000/10000 [02:38<00:00, 62.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 1.1802581740003006\n",
      "Sampling of 10000 batches: 159.70133984299991\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer5(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:00<00:00, 2626853.78it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 584.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.4241142740002033\n",
      "Sampling of 10000 batches: 16.318693213999723\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer6(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:02<00:00, 985910.89it/s] \n",
      "100%|██████████| 10000/10000 [00:16<00:00, 596.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 1.0350060809996648\n",
      "Sampling of 10000 batches: 16.589127244999872\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer7(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:00<00:00, 2744802.58it/s]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]/tmp/ipykernel_10422/1524888231.py:98: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /croot/pytorch-select_1700158693612/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  return list(map(torch.Tensor, list(zip(*batch))))\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 564.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.3841596349993779\n",
      "Sampling of 10000 batches: 16.850195649999478\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer8(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1836881.10it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 42478.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.7609448889998021\n",
      "Sampling of 10000 batches: 0.23952373599968269\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer9(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1792246.89it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 6025.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.7767183719997774\n",
      "Sampling of 10000 batches: 1.6790301529999851\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer10(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
